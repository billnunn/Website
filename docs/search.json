[
  {
    "objectID": "28-10-23.html",
    "href": "28-10-23.html",
    "title": "X-ray Crystallography",
    "section": "",
    "text": "Introduction\nMost people interested in science have heard of x-ray crystallography. Hearing of is one thing, but like me until very recently, one may only have a very limited idea of what a x-ray crystallography experiment involves. Here is what I might have told you before having a chance to inform myself: we take a crystalline sample (I suppose it must be possible to make some proteins into crystals then), shine a beam of x-rays through the sample at different angles, measure a set of diffraction patterns produced, and then use the diffraction patterns to deduce the 3D structure of the sample. At a surface level this is a correct enough overview, but the correctness obscures three horrors:\n\nI didn’t know what a diffraction pattern was.\nAs for the magic final step, I was at a total loss.\nI wasn’t certain what “crystalline” meant in these circumstances. Furthermore why does our sample need to be a crystalline?\n\nIn this post I address these three horrors, mathematically of course.\n\n\nDiffraction Patterns\n\n\nRecovering the Structure\n\n\nWhy Crystals?\n\n\nFinal Comments\nI hope that these short sections have given you some idea of the maths x-ray crystallography involves.\nInterestingly, crystal samples aren’t strictly necessary for diffraction based imaging techniques, ptychography being a key example. Background reading on ptychographic numerical methods is what made me realise I knew so little about x-ray crystallography!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home Page",
    "section": "",
    "text": "Welcome to my website!\nAbout me: I’m a first year maths PhD at the University of Bath- a member of the 10th SAMBa cohort.\nFor those that might not know SAMBa = Statistical Applied Mathematics at Bath."
  },
  {
    "objectID": "05-11-23.html",
    "href": "05-11-23.html",
    "title": "Memorisation vs Proof",
    "section": "",
    "text": "Let random variable \\(X\\) be distributed like a univariate Gaussian \\(N(\\mu, \\sigma^2)\\). It is very well known that the random variable \\(aX\\) is distributed like \\(N(a \\mu, a^{2} \\sigma^2)\\). Let us call this statement Lemma 1. Lemma 1 is so useful that it’s given without proof as part of the ‘hypothesis testing’ topic in A-level maths. Students who continue engaging with maths after A-level might find themselves making use Lemma 1, without ever having seen a proof. This certainly applied to me.\nMemorising a piece of mathematics without knowing (at least) a sketch of a proof can be dangerous, as I found out recently when requiring a very slight generalisation of Lemma 1. I needed to understand the following:\nQuestion: Let random vector \\(X\\) be distributed like an \\(n\\) dimensional multivariate Gaussian \\(N(\\mu, \\Sigma)\\). Let \\(A\\) be a real \\(m\\) by \\(n\\) matrix, how is the \\(m\\) dimensional random vector \\(AX\\) distributed?\nAnswering this question took me a little while, very embarrassing. Perhaps it would have been immediately obvious if I’d seen a proof of Lemma 1. Moreover, perhaps I would have saved some time and confusion if I’d known that Lemma 1 was only memorised, and I’d never proven it for myself. After some thought I arrived at Lemma 2:\nLemma: Let random vector \\(X\\) be distributed like an \\(n\\) dimensional multivariate Gaussian \\(N(\\mu, \\Sigma)\\). Let \\(A\\) be a real \\(m\\) by \\(n\\) matrix. The \\(m\\) dimensional random vector \\(AX\\) distributed like \\(N(A \\mu, A \\Sigma A^T)\\).\nProof (Sketch): We can see this with multivariate moment generating functions. Recall that for a multivariate Gaussian distribution \\(N(\\mu, \\Sigma )\\) the moment generating function is given by:\n\\[\nMGF(X) = \\mathbb{E}(exp({t^T X})) = exp(\\mu^Tt + \\frac{1}{2}t^T \\Sigma t)\n\\]\nNow, we can write \\(MGF(AX) = \\mathbb{E}(exp({t^T AX})) = \\mathbb{E}(exp({(A^Tt)^T X}))\\). This tells us that the moment generating function of \\(AX\\) can be written as:\n\\[\nMGF(AX) = exp(\\mu^TA^Tt + \\frac{1}{2}(A^Tt)^T \\Sigma A^Tt)\n= exp((A \\mu)^Tt + \\frac{1}{2} t^T A \\Sigma A^Tt).\n\\]\nWe conclude that \\(AX\\) is distributed like \\(N(A\\mu, A \\Sigma A^T)\\), as moment generating functions uniquely determine distributions.\nClosing Thoughts: Every modern mathematician uses results they don’t know how to prove, and it would be extremist to recommend only using a result if one can sketch a proof. I do think we should all try to be aware of when a result we’ve used is only memorised however, and in the case of simple results like Lemma 1, remedy that state of affiars before embarrassment might ensue.\nThe same sort of discussion doesn’t just apply to mathematical results, but also to other things, like opinions."
  },
  {
    "objectID": "sls.html",
    "href": "sls.html",
    "title": "SLS Schedule",
    "section": "",
    "text": "This page details the 2023 Student Led Symposium (SLS) schedule, to the extent it is currently known. Question marks indicate uncertainty, no question mark means the schedule is confirmed. Scroll down and you may see yourself!\n\nSemester 1\n\n\n\n\n\n\n\n\n\n\n\nDate\nPrimary/Backup\nTime\nLocation\nSpeaker(s)\nTopic(s)\n\n\n\n\n03/10/23\nN/A\n1415\n4E 3.19\nDr Phil Trinh\nMatthew Pawely\nKey dates. Doing a PhD- what to expect, and what to be aware of.\n\n\n05/10/23\nN/A\n1315\n4E 3.19\nDr Theresa Smith\nIntroduction to interdisciplinary research projects (IRPs).\n\n\n12/10/23\nN/A\n1315\n4E 3.19\nDr Cameron Smith\nHow to give (and not give) a good talk.\n\n\n19/10/23\nN/A\n1315\n4E 3.19\nDr Marcel Ortgiese\nDr Phil Trinh\nUseful software tools. Useful literature research tools.\nHosting seminars, networking, and asking the right questions\n\n\n26/10/23\nSam M\nAmin\n1315\n4E 3.19\nHenry Lockyer\nDr Phil Trinh\nAll things LaTeX.\nHow to use your training support fund.\n\n\n02/11/23\nCharlie\nBill\n1315\n4E 3.19\nDr Euan Spence\nProducing mathematical writing that will be read, understood, and enjoyed.\n\n\n09/11/23\nAnnie\nChuanjie\n1315\n4E 3.19\nBeth Stokes\nSeb Scott\nKat Phillips\nHenry Writer\nOutreach, Maths Communication, and Behind the Research.\n\n\n16/11/23\nKamran\nSangeetha\n1315\n4E 3.19\nTimothy Peters\nHenry Lockyer\nDr Phil Trinh\nNimbus and getting the HPC working.\n\n\n23/11/23\nJoanna\nMiles\n1315\n4E 3.19\nJenny Power\nTimothy Peters\nWhat to do during an ITT.\n\n\n30/11/23\nCaroline\nPaddy\n1245 Lunch\n1315 Meeting\n8W 2.10\nDr John Bagnall\nDr Will Kearney\nITT preparation with Wessex Water.\n\n\n06/12/23\nSam W\nYasir\n1315\n4W 1.2\nDr Shaunagh Downing\nITT preparation with CameraForensics.\n\n\n14/12/23\nN/A\n1315\n4W 1.2\nDr Theresa Smith\nIRP presentations.\n\n\nWeek 12\n?\n?\n?\n?\n?\n\n\n\n\n\n\n\n\n\n\n\nThe first ITT takes place in January.\n\n\nSemester 2\n\n\n\n\n\n\n\n\n\n\n\nDate\nPrimary/Backup\nTime\nLocation\nSpeaker(s)\nTopic(s)\n\n\n\n\nWeek 1\nChuanjie\nAnnie\n1515\n8W 2.29\nPhil Trinh\nMarcel Ortgiese\nReflecting on ITT.\n\n\nWeek 2\nBill\n?\n?\nDr Ben Walker\nvisualPDE training.\n\n\nWeek 3\nAnnie\nJoanna\n?\n?\nChiara Boetti\nHenry Writer\nVeronika Chronholm\nPresentations (could swap with week 2)\n\n\nWeek 4\nPaddy\nCaroline\n?\n?\nAsk Tamsin Smith for starters.\nReading (your own) mathematical work critically. (Could be swapped to week 5).\n\n\nWeek 5\nYasir\nSam W\n?\n?\nFind the bitterest students.\nChoosing a supervisor.\n\n\nWeek 6\nSangeetha\nAmin\n?\n?\nDr Ben Adams\nGenAI?\n\n\nWeek 7\nCharlie\nChuanjie\n?\n?\nEmma Bowely\nMathematics and statistics in government?\n\n\nWeek 8\nCharlie\nAmin\n?\n?\n?\nITT partner 1?\n\n\nWeek 9\nSangeetha\nAnnie\n?\n?\n?\nITT partner 2?\n\n\nWeek 10\nKamran\nSam M\n?\n?\n?\nUndecided. Github and version control? Homepage?\n\n\nWeek 11\nSam W\nYasir\n?\n?\nAsk exec for students who’ve done internships\nUndecided. Internships and other career opportunities?\n\n\nWeek 12\n?\n?\n?\n?\n?"
  },
  {
    "objectID": "maths.html",
    "href": "maths.html",
    "title": "Maths",
    "section": "",
    "text": "This page contains four distinct sections:\n\nDigests- Succinct written pieces explaining particularly neat ideas I’ve learnt about.\nProblems- Explanations of any briefly stated problem I’m currently stumped by. Problems which get resolved may be turned into digests.\nTalks- Slides or posters to presentations I’ve given.\nPreprints/Publications- Self explanatory.\n\nEach section is internally ordered by date, with the most recently written documents highest.\n\nDigests\nMemorisation vs proof\nX-ray crystallography\nAn alternative proof\n\n\nProblems\n\n\nTalks\n\n\nPreprints/Publications"
  },
  {
    "objectID": "04-10-23.html",
    "href": "04-10-23.html",
    "title": "An alternative proof",
    "section": "",
    "text": "I encountered this exercise on the first sheet of a ‘Numerical Linear Algebra’ module.\nProblem Statement: Let \\(U\\) be an \\(n\\) by \\(n\\) upper triangular matrix which is zero along the diagonal, show \\(U^n=0\\). In other words, show that such a \\(U\\) is nilpotent.\nThoughts: The standard solution is to consider how the matrix \\(U\\) acts on each of the standard basis vectors: the image of \\(U^k\\) is the span of the remaining \\(n-k\\) vectors.\nAn alternative way to approach the problem (and the approach I thought of before the standard solution) is to view \\(U\\) as an adjacency matrix of a weighted digraph.\nLet’s restrict our view to a special matrix \\(S\\) which has one in all it’s entries above the diagonal. Consider a graph \\(G\\) of \\(n\\) nodes labelled \\(1\\) to \\(n\\), and let \\(S\\) be the adjacency matrix. This is a complete digraph that has each directed from the node with the smaller label to the node with the larger label.\nNow, the \\((i,j)\\)th entry of matrix \\(S^k\\) is the number of directed paths of length \\(k\\) from node \\(i\\) to node \\(j\\). The longest directed path in graph \\(G\\) is the the path \\(1,2,3,…,n\\) but this only has length \\(n-1\\), and we conclude that \\(S^n=0\\).\nThe proof adapts fairly easily to matrix \\(U\\), but is a bit messier. We start with a new notation: for directed path \\(P\\) we let \\(E_m(P)\\) denote the weight of the \\(m\\)th directed edge. The way we can adapt the proof is to observe that the \\((i,j)\\)th entry of matrix of \\(U^k\\) is given by:\n\\[\n\\sum_{P}\\prod_{m=1}^{k}E_m(P)\n\\]\nWhere we are summing over the directed paths \\(P\\) of length \\(k\\) from \\(i\\) to \\(j\\)."
  }
]